{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c60abdd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Reference:\n",
    "- ## https://velog.io/@yeah7598/KoGPT2-%EB%8F%99%ED%99%94-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%95%99%EC%8A%B5%ED%95%98%EA%B8%B0\n",
    "- ## https://github.com/ttop32/KoGPT2novel\n",
    "- ## inference: https://github.com/ttop32/KoGPT2novel/blob/main/train.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8314e386",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\gpu2.6\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Free allocated memory (for CUDA out of memeory error)\n",
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e704ce49",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\master\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers \n",
    "from transformers import PreTrainedTokenizerFast\n",
    "# from transformers import AutoModelWithLMHead # ì´ ë¼ì¸ì´ í•„ìš”í•œì§€ í™•ì¸\n",
    "from fastai.text.all import *\n",
    "import fastai\n",
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "from transformers import GPT2LMHeadModel # Using only GPT2LM Head Model\n",
    "from transformers import PreTrainedTokenizerFast # tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ec768a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.21.1\n",
      "  Using cached transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp37-cp37m-win_amd64.whl (153 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1-cp37-cp37m-win_amd64.whl (3.3 MB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\hp\\anaconda3\\envs\\maaster\\lib\\site-packages (from transformers==4.21.1) (4.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\envs\\maaster\\lib\\site-packages (from transformers==4.21.1) (2.27.1)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\envs\\maaster\\lib\\site-packages (from transformers==4.21.1) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\envs\\maaster\\lib\\site-packages (from transformers==4.21.1) (1.21.5)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.8.17-cp37-cp37m-win_amd64.whl (263 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\envs\\maaster\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21.1) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\envs\\maaster\\lib\\site-packages (from packaging>=20.0->transformers==4.21.1) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\envs\\maaster\\lib\\site-packages (from tqdm>=4.27->transformers==4.21.1) (0.4.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp\\anaconda3\\envs\\maaster\\lib\\site-packages (from importlib-metadata->transformers==4.21.1) (3.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\maaster\\lib\\site-packages (from requests->transformers==4.21.1) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\envs\\maaster\\lib\\site-packages (from requests->transformers==4.21.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\maaster\\lib\\site-packages (from requests->transformers==4.21.1) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\maaster\\lib\\site-packages (from requests->transformers==4.21.1) (2022.6.15)\n",
      "Installing collected packages: tokenizers, tqdm, regex, pyyaml, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.8.0 huggingface-hub-0.8.1 pyyaml-6.0 regex-2022.8.17 tokenizers-0.12.1 tqdm-4.64.0 transformers-4.21.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.21.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install fastai"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install keras"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>') \n",
    "tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ GPT-2 ì…ë‹ˆë‹¤.ğŸ˜¤:)l^o\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>') \n",
    "tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ GPT-2 ì…ë‹ˆë‹¤.ğŸ˜¤:)l^o\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b203f0f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì°¨ë¥¼ íƒ€ê³  ì—¬í–‰ì„ ê°€ìš”ì—†ì–´ í˜ë“¤ë©´ë¼ ì—¬ê¸°ë„í•´ì•¼í• ë•ŒëŠ”ê³³ìœ¼ë¡œ ê¸°ì°¨ë¥¼íƒ€ê³  ì´ê³³ì €ê¸°ì°¨ì—¬í–‰ê¸¸ í•œë°¤ ë­‰í´í•œë°”ëŒì´ë‚ ì•„ë¦„ë‹µê²Œ ì €ë…ì—”ì˜¤ì§íˆë°•íŒë§˜ì†ê¹Šê²Œì™„ë²½í•˜ê²Œì—‰ë§ì„¤ë ˆëŠ”ë‚´ì˜†ì—ìˆì–´ ê·¸ë˜ì–¸ì œì¶œë°œê±¸ìŒë‘ê·¼ì‹¬ìŠ¤ë ˆë‹¤ê°€ì™€í’€ ì‚¬ì´ë¡œë©”ê³ ë¯¼ê±°ë¦¬ëŠ”ëª°ë¼ ì´ê¸¸ìˆ˜ìˆê²Œ ì–´ìƒ‰í•œì¸ë“¯í•œìŠ¤ì³ê°€ë“ë– ë‚˜ì˜¨ëŠë‚Œì„ê°ì‹¸ë˜ê·¸ë§Œë‚˜ê²Œë í…ë° ë–¨ë¦¬ëŠ”ì™¸ë¡œìš´ì„¸ìƒê´€ë¬¸ì—ì•ˆì˜¬ë ¤ì›€ì¯¤ì€ëª¨ë“ ìˆœê°„ì•Œì•˜ê¸°ì— ë‚˜ëŠ”ì§€ê¸ˆ\n"
     ]
    }
   ],
   "source": [
    "# Inference with model\n",
    "\n",
    "text = \"\"\"ì°¨ë¥¼ íƒ€ê³  ì—¬í–‰ì„ ê°€ìš”\"\"\"\n",
    "input_ids = tokenizer.encode(text)\n",
    "gen_ids = model.generate(torch.tensor([input_ids]),\n",
    "                           max_length=128,\n",
    "                           repetition_penalty=2.0,\n",
    "                           pad_token_id=tokenizer.pad_token_id,\n",
    "                           eos_token_id=tokenizer.eos_token_id,\n",
    "                           bos_token_id=tokenizer.bos_token_id,\n",
    "                           use_cache=True\n",
    "                        )\n",
    "generated = tokenizer.decode(gen_ids[0,:].tolist())\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a55ddac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
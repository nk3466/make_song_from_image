{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c60abdd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Reference:\n",
    "- ## https://velog.io/@yeah7598/KoGPT2-%EB%8F%99%ED%99%94-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%95%99%EC%8A%B5%ED%95%98%EA%B8%B0\n",
    "- ## https://github.com/ttop32/KoGPT2novel\n",
    "- ## inference: https://github.com/ttop32/KoGPT2novel/blob/main/train.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8314e386",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\gpu2.6\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Free allocated memory (for CUDA out of memeory error)\n",
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e704ce49",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers \n",
    "from transformers import PreTrainedTokenizerFast\n",
    "# from transformers import AutoModelWithLMHead # 이 라인이 필요한지 확인\n",
    "from fastai.text.all import *\n",
    "import fastai\n",
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "from transformers import GPT2LMHeadModel # Using only GPT2LM Head Model\n",
    "from transformers import PreTrainedTokenizerFast # tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49522b4d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['▁안녕',\n",
       " '하',\n",
       " '세',\n",
       " '요.',\n",
       " '▁한국어',\n",
       " '▁G',\n",
       " 'P',\n",
       " 'T',\n",
       " '-2',\n",
       " '▁입',\n",
       " '니다.',\n",
       " '😤',\n",
       " ':)',\n",
       " 'l^o']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>') \n",
    "tokenizer.tokenize(\"안녕하세요. 한국어 GPT-2 입니다.😤:)l^o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f636c9f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"kogpt_model_finetunned_all\") # GPT2LMHeadModel/ AutoModelWithLMHead 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b203f0f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "차를 타고 여행을 가요없어 힘들면돼 여기도해야할때는곳으로 기차를타고 이곳저기차여행길 한밤 뭉클한바람이날아름답게 저녁엔오직히박힌맘속깊게완벽하게엉망설레는내옆에있어 그래언제출발걸음두근심스레다가와풀 사이로메고민거리는몰라 이길수있게 어색한인듯한스쳐가득떠나온느낌을감싸던그만나게될텐데 떨리는외로운세상관문에안올려움쯤은모든순간알았기에 나는지금\n"
     ]
    }
   ],
   "source": [
    "# Inference with model\n",
    "\n",
    "text = \"\"\"차를 타고 여행을 가요\"\"\"\n",
    "input_ids = tokenizer.encode(text)\n",
    "gen_ids = model.generate(torch.tensor([input_ids]),\n",
    "                           max_length=128,\n",
    "                           repetition_penalty=2.0,\n",
    "                           pad_token_id=tokenizer.pad_token_id,\n",
    "                           eos_token_id=tokenizer.eos_token_id,\n",
    "                           bos_token_id=tokenizer.bos_token_id,\n",
    "                           use_cache=True\n",
    "                        )\n",
    "generated = tokenizer.decode(gen_ids[0,:].tolist())\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a55ddac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
